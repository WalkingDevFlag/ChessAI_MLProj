{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **3rd Fucking Approach**"
      ],
      "metadata": {
        "id": "1EcJSjho70mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieving Dataset"
      ],
      "metadata": {
        "id": "mjpYwBiO8f7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chess stockfish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJgpoMfj-fYl",
        "outputId": "ad9a537b-1d0b-43e4-c65f-2a26c7ac4fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chess\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stockfish\n",
            "  Downloading stockfish-3.28.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: stockfish, chess\n",
            "Successfully installed chess-1.10.0 stockfish-3.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/drive/MyDrive/stockfish/stockfish-ubuntu-x86-64-avx2\n",
        "!ls -l /content/drive/MyDrive/stockfish/stockfish-ubuntu-x86-64-avx2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlp0rdez_Z0J",
        "outputId": "7d0a82aa-f89e-40de-bcae-766b240ccf1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwx------ 1 root root 69200160 Feb 24 18:26 /content/drive/MyDrive/stockfish/stockfish-ubuntu-x86-64-avx2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "from stockfish import Stockfish\n",
        "stockfish = Stockfish(path=r\"/content/drive/MyDrive/stockfish/stockfish-ubuntu-x86-64-avx2\")\n",
        "import random\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import time"
      ],
      "metadata": {
        "id": "4Gpu2HyI73lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test checkmate:\n",
        "board = chess.Board()\n",
        "board.push_san(\"e4\")\n",
        "board.push_san(\"e5\")\n",
        "board.push_san(\"Qh5\")\n",
        "board.push_san(\"Nc6\")\n",
        "board.push_san(\"Bc4\")\n",
        "board.push_san(\"Nf6\")\n",
        "board.push_san(\"Qxf7\")\n",
        "board.is_checkmate()\n",
        "# board"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUieHOJm7_L3",
        "outputId": "98b2385b-b52a-422b-8c38-118295d8719a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stockfish intro\n",
        "\n",
        "#set pos from starting pos\n",
        "# stockfish.set_position([\"e2e4\", \"e7e6\"])\n",
        "\n",
        "#set pos from current pos:\n",
        "# stockfish.make_moves_from_current_position([\"g4d7\", \"a8b8\", \"f1d1\"])\n",
        "\n",
        "#get best move\n",
        "stockfish.get_best_move()\n",
        "\n",
        "# Get best move based on a time constraint\n",
        "# stockfish.get_best_move_time(1000)\n",
        "\n",
        "#get current board position with FEN encoding\n",
        "stockfish.get_fen_position()\n",
        "\n",
        "#reset board position:\n",
        "#-> dont need this since we just add to moves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mWCefIkb8Dwq",
        "outputId": "6160cd28-0eee-4fd1-bfe7-964e45dc9e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print chess board from fen position:\n",
        "# fen = \"r1b2rk1/pp2ppbp/1nP2np1/q2PN3/8/2N3P1/PP2PPBP/R1BQK2R b KQ - 2 10\"\n",
        "def fen_to_board(fen):\n",
        "    board = []\n",
        "    for row in fen.split('/'):\n",
        "        brow = []\n",
        "        for c in row:\n",
        "            if c == ' ':\n",
        "                break\n",
        "            elif c in '12345678':\n",
        "                brow.extend( ['--'] * int(c) )\n",
        "            elif c == 'p':\n",
        "                brow.append( 'bp' )\n",
        "            elif c == 'P':\n",
        "                brow.append( 'wp' )\n",
        "            elif c > 'Z':\n",
        "                brow.append( 'b'+c.upper() )\n",
        "            else:\n",
        "                brow.append( 'w'+c )\n",
        "\n",
        "        board.append( brow )\n",
        "    return board\n",
        "\n",
        "# pprint( fen_to_board(fen) )"
      ],
      "metadata": {
        "id": "q-FgHA3d8HDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions:\n",
        "def checkEndCondition(board):\n",
        "\tif (board.is_checkmate() or board.is_stalemate() or board.is_insufficient_material() or board.can_claim_threefold_repetition() or board.can_claim_fifty_moves() or board.can_claim_draw()):\n",
        "\t\treturn True\n",
        "\treturn False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''def saveData(moves, positions):\n",
        "\tmoves = np.array(moves).reshape(-1, 1)\n",
        "\tpositions = np.array(positions).reshape(-1,1)\n",
        "\tmovesAndPositions = np.concatenate((moves, positions), axis = 1)\n",
        "\n",
        "\tnextIdx = findNextIdx()\n",
        "\tnp.save(f\"data/movesAndPositions{nextIdx}.npy\", movesAndPositions)\n",
        "\tprint(\"Saved successfully\")'''\n",
        "\n",
        "\n",
        "def saveData(moves, positions):\n",
        "    moves = np.array(moves).reshape(-1, 1)\n",
        "    positions = np.array(positions).reshape(-1, 1)\n",
        "    movesAndPositions = np.concatenate((moves, positions), axis=1)\n",
        "\n",
        "    nextIdx = findNextIdx()\n",
        "\n",
        "    directory = f\"data{nextIdx}\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    np.save(os.path.join(directory, f\"movesAndPositions{nextIdx}.npy\"), movesAndPositions)\n",
        "    print(\"Saved successfully\")\n",
        "\n",
        "\n",
        "\n",
        "def runGame(numMoves, filename):\n",
        "\t\"\"\"run a game you stored\"\"\"\n",
        "\ttesting = np.load(f\"data1/{filename}\")\n",
        "\tmoves = testing[:, 0]\n",
        "\tif (numMoves > len(moves)):\n",
        "\t\tprint(\"Must enter a lower number of moves than maximum game length. Game length here is: \", len(moves))\n",
        "\t\treturn\n",
        "\n",
        "\ttestBoard = chess.Board()\n",
        "\n",
        "\tfor i in range(numMoves):\n",
        "\t\tmove = moves[i]\n",
        "\t\ttestBoard.push_san(move)\n",
        "\treturn testBoard\n",
        "\n",
        "def findNextIdx():\n",
        "\tfiles = (glob.glob(r\"C:\\Users\\Lenovo\\Desktop\\Chess AI\\New_Approach\\data\\*.npy\"))\n",
        "\tif (len(files) == 0):\n",
        "\t\treturn 1 #if no files, return 1\n",
        "\thighestIdx = 0\n",
        "\tfor f in files:\n",
        "\t\tfile = f\n",
        "\t\tcurrIdx = file.split(\"movesAndPositions\")[-1].split(\".npy\")[0]\n",
        "\t\thighestIdx = max(highestIdx, int(currIdx))\n",
        "\n",
        "\treturn int(highestIdx)+1"
      ],
      "metadata": {
        "id": "1ptLT-OC8KVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mineGames(numGames : int):\n",
        "\t\"\"\"mines numGames games of moves\"\"\"\n",
        "\tMAX_MOVES = 500 #don't continue games after this number\n",
        "\n",
        "\tfor i in range(numGames):\n",
        "\t\tcurrentGameMoves = []\n",
        "\t\tcurrentGamePositions = []\n",
        "\t\tboard = chess.Board()\n",
        "\t\tstockfish.set_position([])\n",
        "\n",
        "\t\tfor i in range(MAX_MOVES):\n",
        "\t\t\t#randomly choose from those 3 moves\n",
        "\t\t\tmoves = stockfish.get_top_moves(3)\n",
        "\t\t\t#if less than 3 moves available, choose first one, if none available, exit\n",
        "\t\t\tif (len(moves) == 0):\n",
        "\t\t\t\tprint(\"game is over\")\n",
        "\t\t\t\tbreak\n",
        "\t\t\telif (len(moves) == 1):\n",
        "\t\t\t\tmove = moves[0][\"Move\"]\n",
        "\t\t\telif (len(moves) == 2):\n",
        "\t\t\t\tmove = random.choices(moves, weights=(80, 20), k=1)[0][\"Move\"]\n",
        "\t\t\telse:\n",
        "\t\t\t\tmove = random.choices(moves, weights=(80, 15, 5), k=1)[0][\"Move\"]\n",
        "\n",
        "\t\t\tcurrentGamePositions.append(stockfish.get_fen_position())\n",
        "\t\t\tcurrentGameMoves.append(move) #make sure to add str version of move before changing format\n",
        "\t\t\tmove = chess.Move.from_uci(str(move)) #convert to format chess package likes\n",
        "\t\t\tboard.push(move)\n",
        "\t\t\tstockfish.set_position(currentGameMoves)\n",
        "\t\t\tif (checkEndCondition(board)):\n",
        "\t\t\t\tprint(\"game is over\")\n",
        "\t\t\t\tbreak\n",
        "\t\tsaveData(currentGameMoves, currentGamePositions)"
      ],
      "metadata": {
        "id": "mPosCTiC8OaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mineGames(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut281y_n8UFt",
        "outputId": "c257cd41-f200-465c-e77b-dc7ee878573e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n",
            "game is over\n",
            "Saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open a game and play it\n",
        "\n",
        "\n",
        "\n",
        "testBoard = runGame(12, \"movesAndPositions1.npy\")\n",
        "testBoard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "sDcdo4Ij8WrB",
        "outputId": "1d1e96db-8be3-4a1c-c5d1-279b78d8e6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnbqk1nr/1p2bppp/p2pp3/8/3NP3/2N3P1/PPP2P1P/R1BQKB1R w KQkq - 1 7')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b q k . n r\n. p . . b p p p\np . . p p . . .\n. . . . . . . .\n. . . N P . . .\n. . N . . . P .\nP P P . . P . P\nR . B Q K B . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark lastmove e7\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark lastmove f8\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(105, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 240)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(150, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding"
      ],
      "metadata": {
        "id": "kkIHaYwP8kH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym gym_chess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "heDBBCoaFdeB",
        "outputId": "6745849e-5101-4ffd-daf1-37c2ff6fb82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting gym_chess\n",
            "  Downloading gym_chess-0.1.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Collecting gym\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-chess<0.32.0,>=0.31.1 (from gym_chess)\n",
            "  Downloading python_chess-0.31.4-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym) (1.11.4)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0 (from gym)\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0 (from gym)\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.3)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654618 sha256=994e00800e55b62e2beac4a6bd339dc856c7f6e211246edaf05102736a3a3ffb\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/4b/74/fcfc8238472c34d7f96508a63c962ff3ac9485a9a4137afd4e\n",
            "Successfully built gym\n",
            "Installing collected packages: python-chess, pyglet, cloudpickle, gym, gym_chess\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.0.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-1.6.0 gym-0.17.3 gym_chess-0.1.1 pyglet-1.5.0 python-chess-0.31.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chess"
                ]
              },
              "id": "063a36844e5d4153b228f6a560224937"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone <repository_url>"
      ],
      "metadata": {
        "id": "d8RjFU7ShzjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import chess\n",
        "import os\n",
        "import gym.spaces\n",
        "from gym_chess.alphazero.move_encoding import utils, queenmoves, knightmoves, underpromotions\n",
        "from typing import List\n",
        "\n",
        "env = gym.make('ChessAlphaZero-v0')"
      ],
      "metadata": {
        "id": "ibpJXrp_8md-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding from gym-chess\n",
        "env = gym.make('ChessAlphaZero-v0')\n",
        "env.reset()\n",
        "print(env.observation_space)\n",
        "print(env.action_space)"
      ],
      "metadata": {
        "id": "KTVhlOpU8qc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7098daf-885d-45e4-8843-d78fddd56018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(0, 9223372036854775807, (8, 8, 119), int64)\n",
            "Discrete(4672)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gym-chess environment:\n",
        "\n",
        "\n",
        "#encode:\n",
        "# move = chess.Move.from_uci('e2e4')\n",
        "# env.encode(move)\n",
        "\n",
        "#decode:\n",
        "env = gym.make('ChessAlphaZero-v0')\n",
        "env.reset()\n",
        "\n",
        "env.decode(1000)\n",
        "\n",
        "\n",
        "# env.legal_actions #moves with encoded notation\n",
        "# env.legal_moves #moves with decoded notation"
      ],
      "metadata": {
        "id": "Qiw3D_su8snO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0805487-63f3-458c-bb2b-5ef26f6ee541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Move.from_uci('f2c5')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding func from alpha zero:\n",
        "\n",
        "\n",
        "def encodeBoardFromFen(fen: str) -> np.array:\n",
        "\tboard = chess.Board(fen)\n",
        "\treturn encodeBoard(board)\n",
        "\n",
        "def encodeBoard(board: chess.Board) -> np.array:\n",
        "\t\"\"\"Converts a board to numpy array representation.\"\"\"\n",
        "\n",
        "\tarray = np.zeros((8, 8, 14), dtype=int)\n",
        "\n",
        "\tfor square, piece in board.piece_map().items():\n",
        "\t\trank, file = chess.square_rank(square), chess.square_file(square)\n",
        "\t\tpiece_type, color = piece.piece_type, piece.color\n",
        "\n",
        "\t\t# The first six planes encode the pieces of the active player,\n",
        "\t\t# the following six those of the active player's opponent. Since\n",
        "\t\t# this class always stores boards oriented towards the white player,\n",
        "\t\t# White is considered to be the active player here.\n",
        "\t\toffset = 0 if color == chess.WHITE else 6\n",
        "\n",
        "\t\t# Chess enumerates piece types beginning with one, which we have\n",
        "\t\t# to account for\n",
        "\t\tidx = piece_type - 1\n",
        "\n",
        "\t\tarray[rank, file, idx + offset] = 1\n",
        "\n",
        "\t# Repetition counters\n",
        "\tarray[:, :, 12] = board.is_repetition(2)\n",
        "\tarray[:, :, 13] = board.is_repetition(3)\n",
        "\n",
        "\treturn array\n",
        "\n",
        "\n",
        "def decodeMove(move: int):\n",
        "\treturn env.decode(move)\n",
        "\n",
        "#fixing encoding funcs from openai\n",
        "\n",
        "def encodeKnight(move: chess.Move):\n",
        "    _NUM_TYPES: int = 8\n",
        "\n",
        "    #: Starting point of knight moves in last dimension of 8 x 8 x 73 action array.\n",
        "    _TYPE_OFFSET: int = 56\n",
        "\n",
        "    #: Set of possible directions for a knight move, encoded as\n",
        "    #: (delta rank, delta square).\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+2, +1),\n",
        "        (+1, +2),\n",
        "        (-1, +2),\n",
        "        (-2, +1),\n",
        "        (-2, -1),\n",
        "        (-1, -2),\n",
        "        (+1, -2),\n",
        "        (+2, -1),\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, to_rank, to_file = utils.unpack(move)\n",
        "\n",
        "    delta = (to_rank - from_rank, to_file - from_file)\n",
        "    is_knight_move = delta in _DIRECTIONS\n",
        "\n",
        "    if not is_knight_move:\n",
        "        return None\n",
        "\n",
        "    knight_move_type = _DIRECTIONS.index(delta)\n",
        "    move_type = _TYPE_OFFSET + knight_move_type\n",
        "\n",
        "    action = np.ravel_multi_index(\n",
        "        multi_index=((from_rank, from_file, move_type)),\n",
        "        dims=(8, 8, 73)\n",
        "    )\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "def encodeQueen(move: chess.Move):\n",
        "    _NUM_TYPES: int = 56 # = 8 directions * 7 squares max. distance\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+1,  0),\n",
        "        (+1, +1),\n",
        "        ( 0, +1),\n",
        "        (-1, +1),\n",
        "        (-1,  0),\n",
        "        (-1, -1),\n",
        "        ( 0, -1),\n",
        "        (+1, -1),\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, to_rank, to_file = utils.unpack(move)\n",
        "\n",
        "    delta = (to_rank - from_rank, to_file - from_file)\n",
        "\n",
        "    is_horizontal = delta[0] == 0\n",
        "    is_vertical = delta[1] == 0\n",
        "    is_diagonal = abs(delta[0]) == abs(delta[1])\n",
        "    is_queen_move_promotion = move.promotion in (chess.QUEEN, None)\n",
        "\n",
        "    is_queen_move = (\n",
        "        (is_horizontal or is_vertical or is_diagonal)\n",
        "            and is_queen_move_promotion\n",
        "    )\n",
        "\n",
        "    if not is_queen_move:\n",
        "        return None\n",
        "\n",
        "    direction = tuple(np.sign(delta))\n",
        "    distance = np.max(np.abs(delta))\n",
        "\n",
        "    direction_idx = _DIRECTIONS.index(direction)\n",
        "    distance_idx = distance - 1\n",
        "\n",
        "    move_type = np.ravel_multi_index(\n",
        "        multi_index=([direction_idx, distance_idx]),\n",
        "        dims=(8,7)\n",
        "    )\n",
        "\n",
        "    action = np.ravel_multi_index(\n",
        "        multi_index=((from_rank, from_file, move_type)),\n",
        "        dims=(8, 8, 73)\n",
        "    )\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "def encodeUnder(move):\n",
        "    _NUM_TYPES: int = 9 # = 3 directions * 3 piece types (see below)\n",
        "    _TYPE_OFFSET: int = 64\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        -1,\n",
        "        0,\n",
        "        +1,\n",
        "    )\n",
        "    _PROMOTIONS = utils.IndexedTuple(\n",
        "        chess.KNIGHT,\n",
        "        chess.BISHOP,\n",
        "        chess.ROOK,\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, to_rank, to_file = utils.unpack(move)\n",
        "\n",
        "    is_underpromotion = (\n",
        "        move.promotion in _PROMOTIONS\n",
        "        and from_rank == 6\n",
        "        and to_rank == 7\n",
        "    )\n",
        "\n",
        "    if not is_underpromotion:\n",
        "        return None\n",
        "\n",
        "    delta_file = to_file - from_file\n",
        "\n",
        "    direction_idx = _DIRECTIONS.index(delta_file)\n",
        "    promotion_idx = _PROMOTIONS.index(move.promotion)\n",
        "\n",
        "    underpromotion_type = np.ravel_multi_index(\n",
        "        multi_index=([direction_idx, promotion_idx]),\n",
        "        dims=(3,3)\n",
        "    )\n",
        "\n",
        "    move_type = _TYPE_OFFSET + underpromotion_type\n",
        "\n",
        "    action = np.ravel_multi_index(\n",
        "        multi_index=((from_rank, from_file, move_type)),\n",
        "        dims=(8, 8, 73)\n",
        "    )\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "def encodeMove(move: str, board) -> int:\n",
        "    move = chess.Move.from_uci(move)\n",
        "    if board.turn == chess.BLACK:\n",
        "        move = utils.rotate(move)\n",
        "\n",
        "    action = encodeQueen(move)\n",
        "\n",
        "    if action is None:\n",
        "        action = encodeKnight(move)\n",
        "\n",
        "    if action is None:\n",
        "        action = encodeUnder(move)\n",
        "\n",
        "    if action is None:\n",
        "        raise ValueError(f\"{move} is not a valid move\")\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "a0XQgpoK8vjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#function to encode all moves and positions from rawData folder\n",
        "def encodeAllMovesAndPositions():\n",
        "    board = chess.Board() #this is used to change whose turn it is so that the encoding works\n",
        "    board.turn = False #set turn to black first, changed on first run\n",
        "\n",
        "    #find all files in folder:\n",
        "    files = os.listdir('/content/data1')\n",
        "    for idx, f in enumerate(files):\n",
        "        movesAndPositions = np.load(f'data1/{f}', allow_pickle=True)\n",
        "        moves = movesAndPositions[:,0]\n",
        "        positions = movesAndPositions[:,1]\n",
        "        encodedMoves = []\n",
        "        encodedPositions = []\n",
        "\n",
        "\n",
        "        for i in range(len(moves)):\n",
        "            board.turn = (not board.turn) #swap turns\n",
        "            try:\n",
        "                encodedMoves.append(encodeMove(moves[i], board))\n",
        "                encodedPositions.append(encodeBoardFromFen(positions[i]))\n",
        "            except:\n",
        "                try:\n",
        "                    board.turn = (not board.turn) #change turn, since we skip moves sometimes, we might need to change turn\n",
        "                    encodedMoves.append(encodeMove(moves[i], board))\n",
        "                    encodedPositions.append(encodeBoardFromFen(positions[i]))\n",
        "                except:\n",
        "                    print(f'error in file: {f}')\n",
        "                    print(\"Turn: \", board.turn)\n",
        "                    print(moves[i])\n",
        "                    print(positions[i])\n",
        "                    print(i)\n",
        "                    break\n",
        "\n",
        "        np.save(f'data/preparedData/moves{idx}', np.array(encodedMoves))\n",
        "        np.save(f'data/preparedData/positions{idx}', np.array(encodedPositions))\n",
        "\n",
        "encodeAllMovesAndPositions()\n",
        "\n",
        "#NOTE: shape of files:\n",
        "#moves: (number of moves in gamew)\n",
        "#positions: (number of moves in game, 8, 8, 14) (number of moves in game is including both black and white moves)\n",
        "'''"
      ],
      "metadata": {
        "id": "rWfb6cgI9EjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encodeAllMovesAndPositions():\n",
        "    # Check if the directories exist, create them if not\n",
        "    if not os.path.exists('data1/preparedData'):\n",
        "        os.makedirs('data1/preparedData')\n",
        "\n",
        "    if not os.path.exists('data1'):\n",
        "        print(\"The 'data1' directory doesn't exist. Please ensure it is created and contains the necessary files.\")\n",
        "        return\n",
        "\n",
        "    board = chess.Board()\n",
        "    board.turn = False\n",
        "\n",
        "    files = os.listdir('data1')\n",
        "    for idx, f in enumerate(files):\n",
        "        if not os.path.isfile(f'data1/{f}'):  # Check if it's a file\n",
        "            continue\n",
        "\n",
        "        movesAndPositions = np.load(f'data1/{f}', allow_pickle=True)\n",
        "        moves = movesAndPositions[:, 0]\n",
        "        positions = movesAndPositions[:, 1]\n",
        "        encodedMoves = []\n",
        "        encodedPositions = []\n",
        "\n",
        "        for i in range(len(moves)):\n",
        "            board.turn = (not board.turn)\n",
        "            try:\n",
        "                encodedMoves.append(encodeMove(moves[i], board))\n",
        "                encodedPositions.append(encodeBoardFromFen(positions[i]))\n",
        "            except Exception as e:\n",
        "                print(f'Error in file: {f}')\n",
        "                print(\"Turn: \", board.turn)\n",
        "                print(\"Move:\", moves[i])\n",
        "                print(\"Position:\", positions[i])\n",
        "                print(\"Index:\", i)\n",
        "                print(\"Error:\", e)\n",
        "                break\n",
        "\n",
        "        np.save(f'data1/preparedData/moves{idx}', np.array(encodedMoves))\n",
        "        np.save(f'data1/preparedData/positions{idx}', np.array(encodedPositions))\n",
        "\n",
        "    return None  # Indicate the function is done"
      ],
      "metadata": {
        "id": "uTPJZKu9jgw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "pafxmiDQ9KSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import gym\n",
        "import gym_chess\n",
        "import os\n",
        "import chess\n",
        "from tqdm import tqdm\n",
        "from gym_chess.alphazero.move_encoding import utils\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "BQhPuzWJ9Isr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "cB-cEb7M9UKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856b9b18-ac42-4cff-e446-7f3db455a1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#helper methods:\n",
        "\n",
        "\n",
        "\n",
        "#decoding moves from idx to uci notation\n",
        "\n",
        "def _decodeKnight(action: int) -> Optional[chess.Move]:\n",
        "    _NUM_TYPES: int = 8\n",
        "\n",
        "    #: Starting point of knight moves in last dimension of 8 x 8 x 73 action array.\n",
        "    _TYPE_OFFSET: int = 56\n",
        "\n",
        "    #: Set of possible directions for a knight move, encoded as\n",
        "    #: (delta rank, delta square).\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+2, +1),\n",
        "        (+1, +2),\n",
        "        (-1, +2),\n",
        "        (-2, +1),\n",
        "        (-2, -1),\n",
        "        (-1, -2),\n",
        "        (+1, -2),\n",
        "        (+2, -1),\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_knight_move = (\n",
        "        _TYPE_OFFSET <= move_type\n",
        "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
        "    )\n",
        "\n",
        "    if not is_knight_move:\n",
        "        return None\n",
        "\n",
        "    knight_move_type = move_type - _TYPE_OFFSET\n",
        "\n",
        "    delta_rank, delta_file = _DIRECTIONS[knight_move_type]\n",
        "\n",
        "    to_rank = from_rank + delta_rank\n",
        "    to_file = from_file + delta_file\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    return move\n",
        "\n",
        "def _decodeQueen(action: int) -> Optional[chess.Move]:\n",
        "\n",
        "    _NUM_TYPES: int = 56 # = 8 directions * 7 squares max. distance\n",
        "\n",
        "    #: Set of possible directions for a queen move, encoded as\n",
        "    #: (delta rank, delta square).\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+1,  0),\n",
        "        (+1, +1),\n",
        "        ( 0, +1),\n",
        "        (-1, +1),\n",
        "        (-1,  0),\n",
        "        (-1, -1),\n",
        "        ( 0, -1),\n",
        "        (+1, -1),\n",
        "    )\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_queen_move = move_type < _NUM_TYPES\n",
        "\n",
        "    if not is_queen_move:\n",
        "        return None\n",
        "\n",
        "    direction_idx, distance_idx = np.unravel_index(\n",
        "        indices=move_type,\n",
        "        shape=(8,7)\n",
        "    )\n",
        "\n",
        "    direction = _DIRECTIONS[direction_idx]\n",
        "    distance = distance_idx + 1\n",
        "\n",
        "    delta_rank = direction[0] * distance\n",
        "    delta_file = direction[1] * distance\n",
        "\n",
        "    to_rank = from_rank + delta_rank\n",
        "    to_file = from_file + delta_file\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    return move\n",
        "\n",
        "def _decodeUnderPromotion(action):\n",
        "    _NUM_TYPES: int = 9 # = 3 directions * 3 piece types (see below)\n",
        "\n",
        "    #: Starting point of underpromotions in last dimension of 8 x 8 x 73 action\n",
        "    #: array.\n",
        "    _TYPE_OFFSET: int = 64\n",
        "\n",
        "    #: Set of possibel directions for an underpromotion, encoded as file delta.\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        -1,\n",
        "        0,\n",
        "        +1,\n",
        "    )\n",
        "\n",
        "    #: Set of possibel piece types for an underpromotion (promoting to a queen\n",
        "    #: is implicitly encoded by the corresponding queen move).\n",
        "    _PROMOTIONS = utils.IndexedTuple(\n",
        "        chess.KNIGHT,\n",
        "        chess.BISHOP,\n",
        "        chess.ROOK,\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_underpromotion = (\n",
        "        _TYPE_OFFSET <= move_type\n",
        "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
        "    )\n",
        "\n",
        "    if not is_underpromotion:\n",
        "        return None\n",
        "\n",
        "    underpromotion_type = move_type - _TYPE_OFFSET\n",
        "\n",
        "    direction_idx, promotion_idx = np.unravel_index(\n",
        "        indices=underpromotion_type,\n",
        "        shape=(3,3)\n",
        "    )\n",
        "\n",
        "    direction = _DIRECTIONS[direction_idx]\n",
        "    promotion = _PROMOTIONS[promotion_idx]\n",
        "\n",
        "    to_rank = from_rank + 1\n",
        "    to_file = from_file + direction\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    move.promotion = promotion\n",
        "\n",
        "    return move\n",
        "\n",
        "#primary decoding function, the ones above are just helper functions\n",
        "def decodeMove(action: int, board) -> chess.Move:\n",
        "        move = _decodeQueen(action)\n",
        "        is_queen_move = move is not None\n",
        "\n",
        "        if not move:\n",
        "            move = _decodeKnight(action)\n",
        "\n",
        "        if not move:\n",
        "            move = _decodeUnderPromotion(action)\n",
        "\n",
        "        if not move:\n",
        "            raise ValueError(f\"{action} is not a valid action\")\n",
        "\n",
        "        # Actions encode moves from the perspective of the current player. If\n",
        "        # this is the black player, the move must be reoriented.\n",
        "        turn = board.turn\n",
        "\n",
        "        if turn == False: #black to move\n",
        "            move = utils.rotate(move)\n",
        "\n",
        "        # Moving a pawn to the opponent's home rank with a queen move\n",
        "        # is automatically assumed to be queen underpromotion. However,\n",
        "        # since queenmoves has no reference to the board and can thus not\n",
        "        # determine whether the moved piece is a pawn, we have to add this\n",
        "        # information manually here\n",
        "        if is_queen_move:\n",
        "            to_rank = chess.square_rank(move.to_square)\n",
        "            is_promoting_move = (\n",
        "                (to_rank == 7 and turn == True) or\n",
        "                (to_rank == 0 and turn == False)\n",
        "            )\n",
        "\n",
        "\n",
        "            piece = board.piece_at(move.from_square)\n",
        "            if piece is None: #NOTE I added this, not entirely sure if it's correct\n",
        "                return None\n",
        "            is_pawn = piece.piece_type == chess.PAWN\n",
        "\n",
        "            if is_pawn and is_promoting_move:\n",
        "                move.promotion = chess.QUEEN\n",
        "\n",
        "        return move\n",
        "\n",
        "def encodeBoard(board: chess.Board) -> np.array:\n",
        "\t\"\"\"Converts a board to numpy array representation.\"\"\"\n",
        "\n",
        "\tarray = np.zeros((8, 8, 14), dtype=int)\n",
        "\n",
        "\tfor square, piece in board.piece_map().items():\n",
        "\t\trank, file = chess.square_rank(square), chess.square_file(square)\n",
        "\t\tpiece_type, color = piece.piece_type, piece.color\n",
        "\n",
        "\t\t# The first six planes encode the pieces of the active player,\n",
        "\t\t# the following six those of the active player's opponent. Since\n",
        "\t\t# this class always stores boards oriented towards the white player,\n",
        "\t\t# White is considered to be the active player here.\n",
        "\t\toffset = 0 if color == chess.WHITE else 6\n",
        "\n",
        "\t\t# Chess enumerates piece types beginning with one, which we have\n",
        "\t\t# to account for\n",
        "\t\tidx = piece_type - 1\n",
        "\n",
        "\t\tarray[rank, file, idx + offset] = 1\n",
        "\n",
        "\t# Repetition counters\n",
        "\tarray[:, :, 12] = board.is_repetition(2)\n",
        "\tarray[:, :, 13] = board.is_repetition(3)\n",
        "\n",
        "\treturn array"
      ],
      "metadata": {
        "id": "U1y6Wtdh9VFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FRACTION_OF_DATA = 1\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "OugT54G89c_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "allMoves = []\n",
        "allBoards = []\n",
        "\n",
        "files = os.listdir('data1/preparedData')\n",
        "numOfEach = len(files) // 2  # Half are moves, other half are positions\n",
        "\n",
        "for i in range(numOfEach):\n",
        "    try:\n",
        "        moves = np.load(f\"data1/preparedData/moves{i}.npy\", allow_pickle=True)\n",
        "        boards = np.load(f\"data1/preparedData/positions{i}.npy\", allow_pickle=True)\n",
        "        if len(moves) != len(boards):\n",
        "            print(\"ERROR ON i =\", i, len(moves), len(boards))\n",
        "        allMoves.extend(moves)\n",
        "        allBoards.extend(boards)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for index {i}: {e}\")\n",
        "\n",
        "print(\"Length of allMoves:\", len(allMoves))\n",
        "print(\"Length of allBoards:\", len(allBoards))\n",
        "\n",
        "# Print some samples to verify data loading\n",
        "print(\"Sample moves:\", allMoves[:5])\n",
        "print(\"Sample boards:\", allBoards[:5])\n",
        "\n",
        "\n",
        "allMoves = np.array(allMoves)[:(int(len(allMoves) * FRACTION_OF_DATA))]\n",
        "allBoards = np.array(allBoards)[:(int(len(allBoards) * FRACTION_OF_DATA))]\n",
        "assert len(allMoves) == len(allBoards), \"MUST BE OF SAME LENGTH\"\n",
        "\n",
        "\n",
        "#flatten out boards\n",
        "# allBoards = allBoards.reshape(allBoards.shape[0], -1)\n",
        "\n",
        "trainDataIdx = int(len(allMoves) * 0.8)\n",
        "\n",
        "#NOTE transfer all data to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "allBoards = torch.from_numpy(np.asarray(allBoards)).to(device)\n",
        "allMoves = torch.from_numpy(np.asarray(allMoves)).to(device)\n",
        "\n",
        "training_set = torch.utils.data.TensorDataset(allBoards[:trainDataIdx], allMoves[:trainDataIdx])\n",
        "test_set = torch.utils.data.TensorDataset(allBoards[trainDataIdx:], allMoves[trainDataIdx:])\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"loaded {len(allMoves)} moves and positions\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0vLpMBhR-7n",
        "outputId": "11deebf3-4e63-4ea9-8702-cc7d506e68ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of allMoves: 327\n",
            "Length of allBoards: 327\n",
            "Sample moves: [804, 129, 876, 657, 657]\n",
            "Sample boards: [array([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]], dtype=int32), array([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]], dtype=int32), array([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]], dtype=int32), array([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]], dtype=int32), array([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]], dtype=int32)]\n",
            "loaded 327 moves and positions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# load dataset\n",
        "\n",
        "#loading training data\n",
        "\n",
        "allMoves = []\n",
        "allBoards = []\n",
        "\n",
        "files = os.listdir('data1/preparedData')\n",
        "numOfEach = len(files) // 2 # half are moves, other half are positions\n",
        "\n",
        "for i in range(numOfEach):\n",
        "    try:\n",
        "        moves = np.load(f\"data/preparedData/moves{i}.npy\", allow_pickle=True)\n",
        "        boards = np.load(f\"data/preparedData/positions{i}.npy\", allow_pickle=True)\n",
        "        if (len(moves) != len(boards)):\n",
        "            print(\"ERROR ON i = \", i, len(moves), len(boards))\n",
        "        allMoves.extend(moves)\n",
        "        allBoards.extend(boards)\n",
        "    except:\n",
        "        # print(\"error: could not load \", i, \", but is still going\")\n",
        "        pass\n",
        "\n",
        "\n",
        "allMoves = np.array(allMoves)[:(int(len(allMoves) * FRACTION_OF_DATA))]\n",
        "allBoards = np.array(allBoards)[:(int(len(allBoards) * FRACTION_OF_DATA))]\n",
        "assert len(allMoves) == len(allBoards), \"MUST BE OF SAME LENGTH\"\n",
        "\n",
        "\n",
        "#flatten out boards\n",
        "# allBoards = allBoards.reshape(allBoards.shape[0], -1)\n",
        "\n",
        "trainDataIdx = int(len(allMoves) * 0.8)\n",
        "\n",
        "#NOTE transfer all data to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "allBoards = torch.from_numpy(np.asarray(allBoards)).to(device)\n",
        "allMoves = torch.from_numpy(np.asarray(allMoves)).to(device)\n",
        "\n",
        "training_set = torch.utils.data.TensorDataset(allBoards[:trainDataIdx], allMoves[:trainDataIdx])\n",
        "test_set = torch.utils.data.TensorDataset(allBoards[trainDataIdx:], allMoves[trainDataIdx:])\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"loaded {len(allMoves)} moves and positions\")\n",
        "'''"
      ],
      "metadata": {
        "id": "z_is7YKg9fYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.INPUT_SIZE = 896\n",
        "        # self.INPUT_SIZE = 7*7*13 #NOTE changing input size for using cnns\n",
        "        self.OUTPUT_SIZE = 4672 # = number of unique moves (action space)\n",
        "\n",
        "\t\t#can try to add CNN and pooling here (calculations taking into account spacial features)\n",
        "\n",
        "        #input shape for sample is (8,8,14), flattened to 1d array of size 896\n",
        "        # self.cnn1 = nn.Conv3d(4,4,(2,2,4), padding=(0,0,1))\n",
        "\n",
        "        self.activation = torch.nn.Tanh()\n",
        "        # self.activation = torch.nn.ReLU()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(self.INPUT_SIZE, 1000)\n",
        "        self.linear2 = torch.nn.Linear(1000, 1000)\n",
        "        self.linear3 = torch.nn.Linear(1000, 1000)\n",
        "        self.linear4 = torch.nn.Linear(1000, 200)\n",
        "        self.linear5 = torch.nn.Linear(200, self.OUTPUT_SIZE)\n",
        "        self.softmax = torch.nn.Softmax(1) #use softmax as prob for each move, dim 1 as dim 0 is the batch dimension\n",
        "\n",
        "    def forward(self, x): #x.shape = (batch size, 896)\n",
        "        x = x.to(torch.float32)\n",
        "        # x = self.cnn1(x) #for using cnns\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear4(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear5(x)\n",
        "        # x = self.softmax(x) #do not use softmax since you are using cross entropy loss\n",
        "        return x\n",
        "\n",
        "    def predict(self, board : chess.Board):\n",
        "        \"\"\"takes in a chess board and returns a chess.move object. NOTE: this function should definitely be written better, but it works for now\"\"\"\n",
        "        with torch.no_grad():\n",
        "            encodedBoard = encodeBoard(board)\n",
        "            encodedBoard = encodedBoard.reshape(1, -1)\n",
        "            encodedBoard = torch.from_numpy(encodedBoard)\n",
        "            res = self.forward(encodedBoard)\n",
        "            probs = self.softmax(res)\n",
        "\n",
        "            probs = probs.numpy()[0] #do not want tensor anymore, 0 since it is a 2d array with 1 row\n",
        "\n",
        "            #verify that move is legal and can be decoded before returning\n",
        "            while len(probs) > 0: #try max 100 times, if not throw an error\n",
        "                moveIdx = probs.argmax()\n",
        "                try: #TODO should not have try here, but was a bug with idx 499 if it is black to move\n",
        "                    uciMove = decodeMove(moveIdx, board)\n",
        "                    if (uciMove is None): #could not decode\n",
        "                        probs = np.delete(probs, moveIdx)\n",
        "                        continue\n",
        "                    move = chess.Move.from_uci(str(uciMove))\n",
        "                    if (move in board.legal_moves): #if legal, return, else: loop continues after deleting the move\n",
        "                        return move\n",
        "                except:\n",
        "                    pass\n",
        "                probs = np.delete(probs, moveIdx) #TODO probably better way to do this, but it is not too time critical as it is only for predictions\n",
        "                                             #remove the move so its not chosen again next iteration\n",
        "\n",
        "            #return random move if model failed to find move\n",
        "            moves = board.legal_moves\n",
        "            if (len(moves) > 0):\n",
        "                return np.random.choice(list(moves))\n",
        "            return None #if no legal moves found, return None\n",
        "            # raise Exception(\"Your predict function could not find any legal/decodable moves\")"
      ],
      "metadata": {
        "id": "Uino3YjU9ja4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions for training\n",
        "def train_one_epoch(model, optimizer, loss_fn, epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            # print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "def createBestModelFile():\n",
        "    #first find best model if it exists:\n",
        "    path = Path('./savedModels/bestModel.txt')\n",
        "\n",
        "    if not (path.is_file()):\n",
        "        #create the files\n",
        "        f = open(path, \"w\")\n",
        "        f.write(\"10000000\") #set to high number so it is overwritten with better loss\n",
        "        f.write(\"\\ntestPath\")\n",
        "        f.close()\n",
        "\n",
        "def saveBestModel(vloss, pathToBestModel):\n",
        "    f = open(\"./savedModels/bestModel.txt\", \"w\")\n",
        "    f.write(str(vloss.item()))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(pathToBestModel)\n",
        "    print(\"NEW BEST MODEL FOUND WITH LOSS:\", vloss)\n",
        "\n",
        "def retrieveBestModelInfo():\n",
        "    with open('./savedModels/bestModel.txt', \"r\") as f:\n",
        "        bestLoss_str = f.readline().strip()\n",
        "        if bestLoss_str:\n",
        "            bestLoss = float(bestLoss_str)\n",
        "        else:\n",
        "            bestLoss = float('inf')  # Set it to infinity or any default value as needed\n",
        "        bestModelPath = f.readline()\n",
        "    return bestLoss, bestModelPath\n",
        "\n",
        "'''\n",
        "def retrieveBestModelInfo():\n",
        "    f = open('./savedModels/bestModel.txt', \"r\")\n",
        "    bestLoss = float(f.readline())\n",
        "    bestModelPath = f.readline()\n",
        "    f.close()\n",
        "    return bestLoss, bestModelPath\n",
        "'''"
      ],
      "metadata": {
        "id": "VIygVX049mjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "46f1d65f-7302-4464-9e63-49e4cfa0818c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef retrieveBestModelInfo():\\n    f = open(\\'./savedModels/bestModel.txt\\', \"r\")\\n    bestLoss = float(f.readline())\\n    bestModelPath = f.readline()\\n    f.close()\\n    return bestLoss, bestModelPath\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def createBestModelFile():\n",
        "    # First find the best model if it exists:\n",
        "    path = Path('./savedModels/bestModel.txt')\n",
        "\n",
        "    # Check if the file exists, if not, create it\n",
        "    if not path.is_file():\n",
        "        try:\n",
        "            # Create the file\n",
        "            with open(path, \"w\") as f:\n",
        "                f.write(\"10000000\\n\") # Set to a high number so it is overwritten with better loss\n",
        "                f.write(\"testPath\\n\") # Example content, modify as needed\n",
        "            print(\"File '{}' created successfully.\".format(path))\n",
        "        except Exception as e:\n",
        "            print(\"Error creating file '{}': {}\".format(path, e))\n",
        "    else:\n",
        "        print(\"File '{}' already exists.\".format(path))\n",
        "\n",
        "def saveBestModel(vloss, pathToBestModel):\n",
        "    path = Path('./savedModels/bestModel.txt')\n",
        "\n",
        "    try:\n",
        "        # Write the new best model information to the file\n",
        "        with open(path, \"w\") as f:\n",
        "            f.write(str(vloss.item()) + \"\\n\")\n",
        "            f.write(pathToBestModel + \"\\n\")\n",
        "        print(\"NEW BEST MODEL FOUND WITH LOSS:\", vloss)\n",
        "    except Exception as e:\n",
        "        print(\"Error saving best model information to file '{}': {}\".format(path, e))\n",
        "\n",
        "def retrieveBestModelInfo():\n",
        "    path = Path('./savedModels/bestModel.txt')\n",
        "\n",
        "    try:\n",
        "        # Read the best loss and model path from the file\n",
        "        with open(path, \"r\") as f:\n",
        "            bestLoss = float(f.readline())\n",
        "            bestModelPath = f.readline().strip()\n",
        "        return bestLoss, bestModelPath\n",
        "    except Exception as e:\n",
        "        print(\"Error retrieving best model information from file '{}': {}\".format(path, e))\n",
        "'''"
      ],
      "metadata": {
        "id": "vB62Gy1_Td9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('./savedModels/bestModel.txt')\n",
        "path.parent.mkdir(parents=True, exist_ok=True)\n",
        "path.touch(exist_ok=True)"
      ],
      "metadata": {
        "id": "HTFetAGdUQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparams\n",
        "EPOCHS = 500\n",
        "LEARNING_RATE = 0.0001 # was 0.001\n",
        "MOMENTUM = 0.9"
      ],
      "metadata": {
        "id": "BvC4G67s9oeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run training\n",
        "\n",
        "\n",
        "createBestModelFile()\n",
        "\n",
        "bestLoss, bestModelPath = retrieveBestModelInfo()\n",
        "\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "model = Model()\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    if (epoch_number % 5 == 0):\n",
        "        print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(model, optimizer, loss_fn, epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "\n",
        "    #only print every 5 epochs\n",
        "    if epoch_number % 5 == 0:\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "\n",
        "        if (bestLoss > best_vloss): #if better than previous best loss from all models created, save it\n",
        "            model_path = 'savedModels/model_{}_{}'.format(timestamp, epoch_number)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            saveBestModel(best_vloss, model_path)\n",
        "\n",
        "\n",
        "\n",
        "    epoch_number += 1\n",
        "\n",
        "# print(\"\\n\\nBEST VALIDATION LOSS FOR ALL MODELS: \", bestLoss)"
      ],
      "metadata": {
        "id": "cU_HlKU79srH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ceb02c-d518-42c4-ce62-fbdbf75eca36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "LOSS train 0.0 valid 8.44163990020752\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/500 [00:01<02:28,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 7/500 [00:01<01:07,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "EPOCH 6:\n",
            "LOSS train 0.0 valid 8.441593170166016\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 9/500 [00:01<01:04,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "EPOCH 11:\n",
            "LOSS train 0.0 valid 8.441571235656738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 11/500 [00:02<01:20,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 12/500 [00:02<01:27,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 13/500 [00:02<01:32,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 15/500 [00:02<01:27,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "EPOCH 16:\n",
            "LOSS train 0.0 valid 8.441558837890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 17/500 [00:03<01:31,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4416, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 18/500 [00:03<01:56,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 20/500 [00:04<01:47,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "EPOCH 21:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 21/500 [00:04<01:53,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.441522598266602\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 22/500 [00:04<01:53,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 25/500 [00:05<01:33,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "EPOCH 26:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 26/500 [00:05<01:34,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.441503524780273\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 28/500 [00:05<01:33,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 30/500 [00:06<01:27,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 33/500 [00:06<00:49,  9.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 31:\n",
            "LOSS train 0.0 valid 8.44148063659668\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 37/500 [00:06<00:41, 11.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "EPOCH 36:\n",
            "LOSS train 0.0 valid 8.4414644241333\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 41/500 [00:06<00:29, 15.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 41:\n",
            "LOSS train 0.0 valid 8.441452026367188\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4415, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 45/500 [00:06<00:30, 15.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "EPOCH 46:\n",
            "LOSS train 0.0 valid 8.441411972045898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 47/500 [00:07<00:30, 14.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 52/500 [00:07<00:25, 17.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "EPOCH 51:\n",
            "LOSS train 0.0 valid 8.441370010375977\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 58/500 [00:07<00:20, 21.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "EPOCH 56:\n",
            "LOSS train 0.0 valid 8.441360473632812\n",
            "EPOCH 61:\n",
            "LOSS train 0.0 valid 8.441352844238281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 64/500 [00:07<00:20, 21.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4414, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 67/500 [00:08<00:21, 20.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "EPOCH 66:\n",
            "LOSS train 0.0 valid 8.441317558288574\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 72/500 [00:08<00:25, 16.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "EPOCH 71:\n",
            "LOSS train 0.0 valid 8.441282272338867\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 77/500 [00:10<01:31,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 76:\n",
            "LOSS train 0.0 valid 8.441256523132324\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4413, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 81/500 [00:10<01:00,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 81:\n",
            "LOSS train 0.0 valid 8.44123649597168\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 85/500 [00:11<00:41, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 86:\n",
            "LOSS train 0.0 valid 8.441230773925781\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 90/500 [00:11<00:36, 11.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 91:\n",
            "LOSS train 0.0 valid 8.44119930267334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 95/500 [00:11<00:27, 14.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 96:\n",
            "LOSS train 0.0 valid 8.441192626953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 102/500 [00:11<00:19, 20.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 101:\n",
            "LOSS train 0.0 valid 8.441178321838379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 108/500 [00:12<00:17, 22.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 106:\n",
            "LOSS train 0.0 valid 8.44117259979248\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 111/500 [00:12<00:20, 18.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "EPOCH 111:\n",
            "LOSS train 0.0 valid 8.441164016723633\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 114/500 [00:12<00:21, 17.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "EPOCH 116:\n",
            "LOSS train 0.0 valid 8.441123962402344\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 121/500 [00:15<01:19,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "EPOCH 121:\n",
            "LOSS train 0.0 valid 8.441102981567383\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 127/500 [00:16<00:44,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "EPOCH 126:\n",
            "LOSS train 0.0 valid 8.441099166870117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 130/500 [00:16<00:39,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "EPOCH 131:\n",
            "LOSS train 0.0 valid 8.441078186035156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 132/500 [00:16<00:39,  9.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 134/500 [00:16<00:38,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4411, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "EPOCH 136:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 136/500 [00:16<00:37,  9.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.44104290008545\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 140/500 [00:17<00:30, 11.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "EPOCH 141:\n",
            "LOSS train 0.0 valid 8.441030502319336\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 142/500 [00:17<00:29, 11.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 146/500 [00:17<00:33, 10.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "EPOCH 146:\n",
            "LOSS train 0.0 valid 8.440988540649414\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 148/500 [00:17<00:33, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 150/500 [00:19<01:58,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n",
            "EPOCH 151:\n",
            "LOSS train 0.0 valid 8.440954208374023\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4410, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 153/500 [00:20<01:41,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "EPOCH 156:\n",
            "LOSS train 0.0 valid 8.440914154052734\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 158/500 [00:20<00:53,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 162/500 [00:21<00:39,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "EPOCH 161:\n",
            "LOSS train 0.0 valid 8.44089412689209\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 170/500 [00:21<00:19, 17.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 166:\n",
            "LOSS train 0.0 valid 8.440905570983887\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "EPOCH 171:\n",
            "LOSS train 0.0 valid 8.440876007080078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 173/500 [00:21<00:19, 17.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "EPOCH 176:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 176/500 [00:21<00:17, 18.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440855026245117\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4409, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 179/500 [00:21<00:17, 17.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "EPOCH 181:\n",
            "LOSS train 0.0 valid 8.44083023071289\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 184/500 [00:22<00:19, 15.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "EPOCH 186:\n",
            "LOSS train 0.0 valid 8.44078254699707\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 190/500 [00:25<01:21,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "EPOCH 191:\n",
            "LOSS train 0.0 valid 8.440765380859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 197/500 [00:26<00:39,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4408, device='cuda:0')\n",
            "EPOCH 196:\n",
            "LOSS train 0.0 valid 8.440750122070312\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 201/500 [00:26<00:30,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "EPOCH 201:\n",
            "LOSS train 0.0 valid 8.440731048583984\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 203/500 [00:26<00:28, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 207/500 [00:26<00:24, 11.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "EPOCH 206:\n",
            "LOSS train 0.0 valid 8.440698623657227\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 211/500 [00:27<00:21, 13.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n",
            "EPOCH 211:\n",
            "LOSS train 0.0 valid 8.440650939941406\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4407, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 215/500 [00:27<00:19, 14.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "EPOCH 216:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 217/500 [00:27<00:18, 15.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440628051757812\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 222/500 [00:27<00:16, 17.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "EPOCH 221:\n",
            "LOSS train 0.0 valid 8.440607070922852\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 226/500 [00:27<00:16, 16.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "EPOCH 226:\n",
            "LOSS train 0.0 valid 8.440572738647461\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 230/500 [00:28<00:16, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4406, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "EPOCH 231:\n",
            "LOSS train 0.0 valid 8.440528869628906\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 234/500 [00:28<00:16, 15.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "EPOCH 236:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 239/500 [00:28<00:14, 18.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440488815307617\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "EPOCH 241:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 242/500 [00:28<00:14, 17.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440479278564453\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 244/500 [00:29<00:18, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 246/500 [00:29<00:20, 12.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "EPOCH 246:\n",
            "LOSS train 0.0 valid 8.440458297729492\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 248/500 [00:29<00:21, 11.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 252/500 [00:29<00:23, 10.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n",
            "EPOCH 251:\n",
            "LOSS train 0.0 valid 8.440452575683594\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4405, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 257/500 [00:30<00:16, 14.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 256:\n",
            "LOSS train 0.0 valid 8.440451622009277\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 261/500 [00:30<00:18, 13.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "EPOCH 261:\n",
            "LOSS train 0.0 valid 8.440423011779785\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 266/500 [00:30<00:15, 14.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "EPOCH 266:\n",
            "LOSS train 0.0 valid 8.440399169921875\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 268/500 [00:30<00:16, 14.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 270/500 [00:31<00:21, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "EPOCH 271:\n",
            "LOSS train 0.0 valid 8.440351486206055"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 272/500 [00:31<00:22, 10.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4404, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 274/500 [00:31<00:21, 10.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "EPOCH 276:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 276/500 [00:31<00:20, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440319061279297\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 278/500 [00:31<00:20, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 280/500 [00:32<00:21, 10.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 281:\n",
            "LOSS train 0.0 valid 8.440261840820312\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4403, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 284/500 [00:32<00:20, 10.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 286/500 [00:32<00:18, 11.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "EPOCH 286:\n",
            "LOSS train 0.0 valid 8.44021224975586\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 290/500 [00:33<00:16, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "EPOCH 291:\n",
            "LOSS train 0.0 valid 8.440156936645508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 292/500 [00:33<00:15, 13.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4402, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 297/500 [00:33<00:12, 16.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "EPOCH 296:\n",
            "LOSS train 0.0 valid 8.44013786315918\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 301/500 [00:33<00:12, 16.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "EPOCH 301:\n",
            "LOSS train 0.0 valid 8.440086364746094\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 306/500 [00:33<00:12, 15.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "EPOCH 306:\n",
            "LOSS train 0.0 valid 8.4400634765625\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 308/500 [00:34<00:13, 14.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4401, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "EPOCH 311:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 314/500 [00:34<00:09, 19.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.440052032470703\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "EPOCH 316:\n",
            "LOSS train 0.0 valid 8.44003677368164\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 321/500 [00:35<00:20,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "EPOCH 321:\n",
            "LOSS train 0.0 valid 8.439970016479492\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 323/500 [00:35<00:17,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4400, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 327/500 [00:36<00:15, 10.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "EPOCH 326:\n",
            "LOSS train 0.0 valid 8.43991756439209\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 331/500 [00:36<00:12, 13.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "EPOCH 331:\n",
            "LOSS train 0.0 valid 8.439874649047852\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 335/500 [00:36<00:11, 14.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4399, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "EPOCH 336:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 337/500 [00:36<00:12, 13.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.439827919006348\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 341/500 [00:37<00:11, 13.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "EPOCH 341:\n",
            "LOSS train 0.0 valid 8.439799308776855\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 343/500 [00:37<00:11, 13.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 347/500 [00:37<00:10, 13.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "EPOCH 346:\n",
            "LOSS train 0.0 valid 8.439769744873047\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 349/500 [00:37<00:11, 13.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4398, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "EPOCH 351:\n",
            "LOSS train 0.0 valid 8.439729690551758\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 353/500 [00:38<00:10, 14.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 357/500 [00:38<00:09, 14.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "EPOCH 356:\n",
            "LOSS train 0.0 valid 8.439708709716797\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 361/500 [00:38<00:08, 16.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "EPOCH 361:\n",
            "LOSS train 0.0 valid 8.439689636230469\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 366/500 [00:38<00:07, 18.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "EPOCH 366:\n",
            "LOSS train 0.0 valid 8.43967056274414\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 371/500 [00:39<00:07, 17.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "EPOCH 371:\n",
            "LOSS train 0.0 valid 8.439653396606445\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 376/500 [00:39<00:07, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4397, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "EPOCH 376:\n",
            "LOSS train 0.0 valid 8.439628601074219\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 380/500 [00:39<00:07, 16.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "EPOCH 381:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 382/500 [00:39<00:07, 16.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.43960189819336\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 388/500 [00:40<00:09, 11.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "EPOCH 386:\n",
            "LOSS train 0.0 valid 8.439556121826172\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4396, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 390/500 [00:40<00:09, 11.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "EPOCH 391:\n",
            "LOSS train 0.0 valid 8.43949031829834\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 394/500 [00:40<00:08, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 398/500 [00:41<00:07, 13.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4395, device='cuda:0')\n",
            "EPOCH 396:\n",
            "LOSS train 0.0 valid 8.439449310302734\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 400/500 [00:41<00:07, 13.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "EPOCH 401:\n",
            "LOSS train 0.0 valid 8.43942642211914\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 404/500 [00:41<00:07, 13.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 408/500 [00:41<00:06, 14.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "EPOCH 406:\n",
            "LOSS train 0.0 valid 8.439400672912598\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 412/500 [00:42<00:05, 15.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4394, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "EPOCH 411:\n",
            "LOSS train 0.0 valid 8.4393310546875\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 414/500 [00:42<00:05, 14.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "EPOCH 416:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 416/500 [00:42<00:06, 13.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.439289093017578\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 418/500 [00:42<00:06, 11.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4393, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 422/500 [00:43<00:07, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tensor(8.4393, device='cuda:0')\n",
            "EPOCH 421:\n",
            "LOSS train 0.0 valid 8.439249038696289\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 424/500 [00:43<00:07, 10.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 426/500 [00:43<00:07, 10.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "EPOCH 426:\n",
            "LOSS train 0.0 valid 8.439203262329102\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 430/500 [00:43<00:06, 11.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4392, device='cuda:0')\n",
            "EPOCH 431:\n",
            "LOSS train 0.0 valid 8.439140319824219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 432/500 [00:43<00:06, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 436/500 [00:44<00:05, 12.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "EPOCH 436:\n",
            "LOSS train 0.0 valid 8.439092636108398\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 438/500 [00:44<00:05, 12.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4391, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 440/500 [00:44<00:05, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "EPOCH 441:\n",
            "LOSS train 0.0 valid 8.439029693603516\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 442/500 [00:44<00:05, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 446/500 [00:45<00:07,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "EPOCH 446:\n",
            "LOSS train 0.0 valid 8.438983917236328\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 448/500 [00:45<00:06,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 452/500 [00:46<00:04, 10.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "EPOCH 451:\n",
            "LOSS train 0.0 valid 8.438959121704102\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4390, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 454/500 [00:46<00:04, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n",
            "EPOCH 456:\n",
            "LOSS train 0.0 valid 8.43889045715332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 458/500 [00:46<00:03, 12.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4389, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 462/500 [00:46<00:02, 13.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "EPOCH 461:\n",
            "LOSS train 0.0 valid 8.438825607299805\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 466/500 [00:47<00:02, 14.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n",
            "EPOCH 466:\n",
            "LOSS train 0.0 valid 8.438758850097656\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4388, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 470/500 [00:47<00:02, 14.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "EPOCH 471:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 472/500 [00:47<00:01, 14.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOSS train 0.0 valid 8.438688278198242\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 476/500 [00:47<00:01, 15.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "EPOCH 476:\n",
            "LOSS train 0.0 valid 8.438653945922852\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4387, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 480/500 [00:48<00:01, 15.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "EPOCH 481:\n",
            "LOSS train 0.0 valid 8.438589096069336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 484/500 [00:48<00:01, 15.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4386, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 486/500 [00:48<00:00, 15.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n",
            "EPOCH 486:\n",
            "LOSS train 0.0 valid 8.438531875610352\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 490/500 [00:48<00:00, 13.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4385, device='cuda:0')\n",
            "EPOCH 491:\n",
            "LOSS train 0.0 valid 8.43844985961914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 492/500 [00:48<00:00, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 496/500 [00:49<00:00,  6.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n",
            "EPOCH 496:\n",
            "LOSS train 0.0 valid 8.438383102416992\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 498/500 [00:50<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4384, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4383, device='cuda:0')\n",
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4383, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:50<00:00,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BEST MODEL FOUND WITH LOSS: tensor(8.4383, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Model**"
      ],
      "metadata": {
        "id": "AtglrRVT-NiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load best model\n",
        "saved_model = Model()\n",
        "import os\n",
        "#load best model path from your file\n",
        "f = open(\"./savedModels/bestModel.txt\", \"r\")\n",
        "bestLoss = float(f.readline())\n",
        "model_path = f.readline()\n",
        "f.close()\n",
        "\n",
        "saved_model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "nXi0ssqm9wRZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0c8aa2e9-7d88-454f-9c59-87e9fed32dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-45baf3a54909>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load best model path from your file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#f = open(\"./savedModels/bestModel.txt\", \"r\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test elo  against stockfish\n",
        "ELO_RATING = 100\n",
        "from stockfish import Stockfish\n",
        "stockfish = Stockfish(path=r\"/content/drive/MyDrive/stockfish/stockfish-ubuntu-x86-64-avx2\")\n",
        "\n",
        "stockfish.set_elo_rating(ELO_RATING)\n",
        "stockfish.set_skill_level(0)"
      ],
      "metadata": {
        "id": "4MzxqPoT9yfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board = chess.Board()\n",
        "allMoves = [] #list of strings for saving moves for setting pos for stockfish\n",
        "\n",
        "MAX_NUMBER_OF_MOVES = 150\n",
        "for i in tqdm(range(MAX_NUMBER_OF_MOVES)): #set a limit for the game\n",
        "\t#first my ai move\n",
        "\ttry:\n",
        "\t\tmove = saved_model.predict(board)\n",
        "\t\tboard.push(move)\n",
        "\t\tallMoves.append(str(move)) #add so stockfish can see\n",
        "\texcept:\n",
        "\t\tprint(\"game over. You lost\")\n",
        "\t\tbreak\n",
        "\t# #then get stockfish move\n",
        "\tstockfish.set_position(allMoves)\n",
        "\tstockfishMove = stockfish.get_best_move_time(1)\n",
        "\tallMoves.append(stockfishMove)\n",
        "\tstockfishMove = chess.Move.from_uci(stockfishMove)\n",
        "\tboard.push(stockfishMove)\n",
        "\n",
        "\n",
        "board"
      ],
      "metadata": {
        "id": "-64wUKaK91sU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "9e8e4376-9641-48d8-9867-bb64351bfc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 26/150 [00:00<00:04, 30.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "game over. You lost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('3bk2r/1ppb1pp1/4nn2/7p/2Ppq2P/3K4/3P2P1/B7 w k - 7 27')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g><radialGradient id=\"check_gradient\"><stop offset=\"0%\" stop-color=\"#ff0000\" stop-opacity=\"1.0\" /><stop offset=\"50%\" stop-color=\"#e70000\" stop-opacity=\"1.0\" /><stop offset=\"100%\" stop-color=\"#9e0000\" stop-opacity=\"0.0\" /></radialGradient></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-bishop\" transform=\"translate(15, 330)\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"check\" fill=\"url(#check_gradient)\" /><use xlink:href=\"#white-king\" transform=\"translate(150, 240)\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(105, 195)\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(150, 195)\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light lastmove e4\" stroke=\"none\" fill=\"#cdd16a\" /><use xlink:href=\"#black-queen\" transform=\"translate(195, 195)\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(330, 195)\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove e5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(330, 150)\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-knight\" transform=\"translate(195, 105)\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-knight\" transform=\"translate(240, 105)\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-bishop\" transform=\"translate(150, 60)\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-bishop\" transform=\"translate(150, 15)\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#play 1 move at a time against stockfish\n",
        "board = chess.Board()\n",
        "stockfish.set_position([])\n",
        "stockfish.set_skill_level(0)\n",
        "allMoves = [] #list of strings for saving moves for setting pos for stockfish\n",
        "try:\n",
        "    move = saved_model.predict(board)\n",
        "    board.push(move)\n",
        "    allMoves.append(str(move)) #add so stockfish can see\n",
        "except:\n",
        "    print(\"game over. You lost\")\n",
        "board"
      ],
      "metadata": {
        "id": "xCLcdLBu-EPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "0b0c913d-ca89-4a74-cef4-7a8105dc7ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnbqkbnr/pppppppp/8/8/8/2N5/PPPPPPPP/R1BQKBNR b KQkq - 1 1')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light lastmove b1\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark lastmove c3\" stroke=\"none\" fill=\"#aaa23b\" /><use xlink:href=\"#white-knight\" transform=\"translate(105, 240)\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stockfish.set_position(allMoves)\n",
        "stockfishMove = stockfish.get_best_move_time(1)\n",
        "allMoves.append(stockfishMove)\n",
        "stockfishMove = chess.Move.from_uci(stockfishMove)\n",
        "board.push(stockfishMove)\n",
        "board"
      ],
      "metadata": {
        "id": "HCQtjzXK-HBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "78b3d8ad-d5d5-4b90-ce9f-26729c1743b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnbqkbnr/pppp1ppp/4p3/8/8/2N5/PPPPPPPP/R1BQKBNR w KQkq - 0 2')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-knight\" transform=\"translate(105, 240)\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light lastmove e6\" stroke=\"none\" fill=\"#cdd16a\" /><use xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark lastmove e7\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stockfish.reset_engine_parameters() #reset elo rating\n",
        "print(saved_model.predict(board))\n",
        "stockfish.set_position([])\n",
        "#play your own game\n",
        "board = chess.Board()\n",
        "#regret move:\n",
        "board.pop()\n",
        "#make my move:\n",
        "moveStr = \"e2e4\"\n",
        "move = chess.Move.from_uci(moveStr)\n",
        "board.push(move)\n",
        "#make ai move:\n",
        "aiMove = saved_model.predict(board)\n",
        "board.push(aiMove)\n",
        "board"
      ],
      "metadata": {
        "id": "Pio5hYze-KWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "4578bae8-24f4-4b5a-d834-12fe27cdbb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b2b4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "pop from empty list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a5905f6db8d2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#regret move:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#make my move:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmoveStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"e2e4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chess/__init__.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstack\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m         \"\"\"\n\u001b[0;32m-> 2096\u001b[0;31m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try to play against old model"
      ],
      "metadata": {
        "id": "NhFNcfdi-URp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import gym\n",
        "import gym_chess\n",
        "import os\n",
        "import chess\n",
        "from tqdm import tqdm\n",
        "from gym_chess.alphazero.move_encoding import utils\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "torch.cuda.is_available()\n",
        "\n",
        "#helper methods:\n",
        "\n",
        "\n",
        "\n",
        "#decoding moves from idx to uci notation\n",
        "\n",
        "def _decodeKnight(action: int) -> Optional[chess.Move]:\n",
        "    _NUM_TYPES: int = 8\n",
        "\n",
        "    #: Starting point of knight moves in last dimension of 8 x 8 x 73 action array.\n",
        "    _TYPE_OFFSET: int = 56\n",
        "\n",
        "    #: Set of possible directions for a knight move, encoded as\n",
        "    #: (delta rank, delta square).\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+2, +1),\n",
        "        (+1, +2),\n",
        "        (-1, +2),\n",
        "        (-2, +1),\n",
        "        (-2, -1),\n",
        "        (-1, -2),\n",
        "        (+1, -2),\n",
        "        (+2, -1),\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_knight_move = (\n",
        "        _TYPE_OFFSET <= move_type\n",
        "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
        "    )\n",
        "\n",
        "    if not is_knight_move:\n",
        "        return None\n",
        "\n",
        "    knight_move_type = move_type - _TYPE_OFFSET\n",
        "\n",
        "    delta_rank, delta_file = _DIRECTIONS[knight_move_type]\n",
        "\n",
        "    to_rank = from_rank + delta_rank\n",
        "    to_file = from_file + delta_file\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    return move\n",
        "\n",
        "def _decodeQueen(action: int) -> Optional[chess.Move]:\n",
        "\n",
        "    _NUM_TYPES: int = 56 # = 8 directions * 7 squares max. distance\n",
        "\n",
        "    #: Set of possible directions for a queen move, encoded as\n",
        "    #: (delta rank, delta square).\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        (+1,  0),\n",
        "        (+1, +1),\n",
        "        ( 0, +1),\n",
        "        (-1, +1),\n",
        "        (-1,  0),\n",
        "        (-1, -1),\n",
        "        ( 0, -1),\n",
        "        (+1, -1),\n",
        "    )\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_queen_move = move_type < _NUM_TYPES\n",
        "\n",
        "    if not is_queen_move:\n",
        "        return None\n",
        "\n",
        "    direction_idx, distance_idx = np.unravel_index(\n",
        "        indices=move_type,\n",
        "        shape=(8,7)\n",
        "    )\n",
        "\n",
        "    direction = _DIRECTIONS[direction_idx]\n",
        "    distance = distance_idx + 1\n",
        "\n",
        "    delta_rank = direction[0] * distance\n",
        "    delta_file = direction[1] * distance\n",
        "\n",
        "    to_rank = from_rank + delta_rank\n",
        "    to_file = from_file + delta_file\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    return move\n",
        "\n",
        "def _decodeUnderPromotion(action):\n",
        "    _NUM_TYPES: int = 9 # = 3 directions * 3 piece types (see below)\n",
        "\n",
        "    #: Starting point of underpromotions in last dimension of 8 x 8 x 73 action\n",
        "    #: array.\n",
        "    _TYPE_OFFSET: int = 64\n",
        "\n",
        "    #: Set of possibel directions for an underpromotion, encoded as file delta.\n",
        "    _DIRECTIONS = utils.IndexedTuple(\n",
        "        -1,\n",
        "        0,\n",
        "        +1,\n",
        "    )\n",
        "\n",
        "    #: Set of possibel piece types for an underpromotion (promoting to a queen\n",
        "    #: is implicitly encoded by the corresponding queen move).\n",
        "    _PROMOTIONS = utils.IndexedTuple(\n",
        "        chess.KNIGHT,\n",
        "        chess.BISHOP,\n",
        "        chess.ROOK,\n",
        "    )\n",
        "\n",
        "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
        "\n",
        "    is_underpromotion = (\n",
        "        _TYPE_OFFSET <= move_type\n",
        "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
        "    )\n",
        "\n",
        "    if not is_underpromotion:\n",
        "        return None\n",
        "\n",
        "    underpromotion_type = move_type - _TYPE_OFFSET\n",
        "\n",
        "    direction_idx, promotion_idx = np.unravel_index(\n",
        "        indices=underpromotion_type,\n",
        "        shape=(3,3)\n",
        "    )\n",
        "\n",
        "    direction = _DIRECTIONS[direction_idx]\n",
        "    promotion = _PROMOTIONS[promotion_idx]\n",
        "\n",
        "    to_rank = from_rank + 1\n",
        "    to_file = from_file + direction\n",
        "\n",
        "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
        "    move.promotion = promotion\n",
        "\n",
        "    return move\n",
        "\n",
        "#primary decoding function, the ones above are just helper functions\n",
        "def decodeMove(action: int, board) -> chess.Move:\n",
        "        move = _decodeQueen(action)\n",
        "        is_queen_move = move is not None\n",
        "\n",
        "        if not move:\n",
        "            move = _decodeKnight(action)\n",
        "\n",
        "        if not move:\n",
        "            move = _decodeUnderPromotion(action)\n",
        "\n",
        "        if not move:\n",
        "            raise ValueError(f\"{action} is not a valid action\")\n",
        "\n",
        "        # Actions encode moves from the perspective of the current player. If\n",
        "        # this is the black player, the move must be reoriented.\n",
        "        turn = board.turn\n",
        "\n",
        "        if turn == False: #black to move\n",
        "            move = utils.rotate(move)\n",
        "\n",
        "        # Moving a pawn to the opponent's home rank with a queen move\n",
        "        # is automatically assumed to be queen underpromotion. However,\n",
        "        # since queenmoves has no reference to the board and can thus not\n",
        "        # determine whether the moved piece is a pawn, we have to add this\n",
        "        # information manually here\n",
        "        if is_queen_move:\n",
        "            to_rank = chess.square_rank(move.to_square)\n",
        "            is_promoting_move = (\n",
        "                (to_rank == 7 and turn == True) or\n",
        "                (to_rank == 0 and turn == False)\n",
        "            )\n",
        "\n",
        "\n",
        "            piece = board.piece_at(move.from_square)\n",
        "            if piece is None: #NOTE I added this, not entirely sure if it's correct\n",
        "                return None\n",
        "            is_pawn = piece.piece_type == chess.PAWN\n",
        "\n",
        "            if is_pawn and is_promoting_move:\n",
        "                move.promotion = chess.QUEEN\n",
        "\n",
        "        return move\n",
        "\n",
        "def encodeBoard(board: chess.Board) -> np.array:\n",
        "\t\"\"\"Converts a board to numpy array representation.\"\"\"\n",
        "\n",
        "\tarray = np.zeros((8, 8, 14), dtype=int)\n",
        "\n",
        "\tfor square, piece in board.piece_map().items():\n",
        "\t\trank, file = chess.square_rank(square), chess.square_file(square)\n",
        "\t\tpiece_type, color = piece.piece_type, piece.color\n",
        "\n",
        "\t\t# The first six planes encode the pieces of the active player,\n",
        "\t\t# the following six those of the active player's opponent. Since\n",
        "\t\t# this class always stores boards oriented towards the white player,\n",
        "\t\t# White is considered to be the active player here.\n",
        "\t\toffset = 0 if color == chess.WHITE else 6\n",
        "\n",
        "\t\t# Chess enumerates piece types beginning with one, which we have\n",
        "\t\t# to account for\n",
        "\t\tidx = piece_type - 1\n",
        "\n",
        "\t\tarray[rank, file, idx + offset] = 1\n",
        "\n",
        "\t# Repetition counters\n",
        "\tarray[:, :, 12] = board.is_repetition(2)\n",
        "\tarray[:, :, 13] = board.is_repetition(3)\n",
        "\n",
        "\treturn array\n",
        "\n",
        "FRACTION_OF_DATA = 1\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load dataset\n",
        "allMoves = []\n",
        "allBoards = []\n",
        "\n",
        "files = os.listdir('data1/preparedData')\n",
        "numOfEach = len(files) // 2  # Half are moves, other half are positions\n",
        "\n",
        "for i in range(numOfEach):\n",
        "    try:\n",
        "        moves = np.load(f\"data1/preparedData/moves{i}.npy\", allow_pickle=True)\n",
        "        boards = np.load(f\"data1/preparedData/positions{i}.npy\", allow_pickle=True)\n",
        "        if len(moves) != len(boards):\n",
        "            print(\"ERROR ON i =\", i, len(moves), len(boards))\n",
        "        allMoves.extend(moves)\n",
        "        allBoards.extend(boards)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for index {i}: {e}\")\n",
        "\n",
        "print(\"Length of allMoves:\", len(allMoves))\n",
        "print(\"Length of allBoards:\", len(allBoards))\n",
        "\n",
        "# Print some samples to verify data loading\n",
        "print(\"Sample moves:\", allMoves[:5])\n",
        "print(\"Sample boards:\", allBoards[:5])\n",
        "\n",
        "\n",
        "allMoves = np.array(allMoves)[:(int(len(allMoves) * FRACTION_OF_DATA))]\n",
        "allBoards = np.array(allBoards)[:(int(len(allBoards) * FRACTION_OF_DATA))]\n",
        "assert len(allMoves) == len(allBoards), \"MUST BE OF SAME LENGTH\"\n",
        "\n",
        "\n",
        "#flatten out boards\n",
        "# allBoards = allBoards.reshape(allBoards.shape[0], -1)\n",
        "\n",
        "trainDataIdx = int(len(allMoves) * 0.8)\n",
        "\n",
        "#NOTE transfer all data to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "allBoards = torch.from_numpy(np.asarray(allBoards)).to(device)\n",
        "allMoves = torch.from_numpy(np.asarray(allMoves)).to(device)\n",
        "\n",
        "training_set = torch.utils.data.TensorDataset(allBoards[:trainDataIdx], allMoves[:trainDataIdx])\n",
        "test_set = torch.utils.data.TensorDataset(allBoards[trainDataIdx:], allMoves[trainDataIdx:])\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"loaded {len(allMoves)} moves and positions\")\n",
        "\n",
        "#model\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.INPUT_SIZE = 896\n",
        "        # self.INPUT_SIZE = 7*7*13 #NOTE changing input size for using cnns\n",
        "        self.OUTPUT_SIZE = 4672 # = number of unique moves (action space)\n",
        "\n",
        "\t\t#can try to add CNN and pooling here (calculations taking into account spacial features)\n",
        "\n",
        "        #input shape for sample is (8,8,14), flattened to 1d array of size 896\n",
        "        # self.cnn1 = nn.Conv3d(4,4,(2,2,4), padding=(0,0,1))\n",
        "\n",
        "        self.activation = torch.nn.Tanh()\n",
        "        # self.activation = torch.nn.ReLU()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(self.INPUT_SIZE, 1000)\n",
        "        self.linear2 = torch.nn.Linear(1000, 1000)\n",
        "        self.linear3 = torch.nn.Linear(1000, 1000)\n",
        "        self.linear4 = torch.nn.Linear(1000, 200)\n",
        "        self.linear5 = torch.nn.Linear(200, self.OUTPUT_SIZE)\n",
        "        self.softmax = torch.nn.Softmax(1) #use softmax as prob for each move, dim 1 as dim 0 is the batch dimension\n",
        "\n",
        "    def forward(self, x): #x.shape = (batch size, 896)\n",
        "        x = x.to(torch.float32)\n",
        "        # x = self.cnn1(x) #for using cnns\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear4(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear5(x)\n",
        "        # x = self.softmax(x) #do not use softmax since you are using cross entropy loss\n",
        "        return x\n",
        "\n",
        "    def predict(self, board : chess.Board):\n",
        "        \"\"\"takes in a chess board and returns a chess.move object. NOTE: this function should definitely be written better, but it works for now\"\"\"\n",
        "        with torch.no_grad():\n",
        "            encodedBoard = encodeBoard(board)\n",
        "            encodedBoard = encodedBoard.reshape(1, -1)\n",
        "            encodedBoard = torch.from_numpy(encodedBoard)\n",
        "            res = self.forward(encodedBoard)\n",
        "            probs = self.softmax(res)\n",
        "\n",
        "            probs = probs.numpy()[0] #do not want tensor anymore, 0 since it is a 2d array with 1 row\n",
        "\n",
        "            #verify that move is legal and can be decoded before returning\n",
        "            while len(probs) > 0: #try max 100 times, if not throw an error\n",
        "                moveIdx = probs.argmax()\n",
        "                try: #TODO should not have try here, but was a bug with idx 499 if it is black to move\n",
        "                    uciMove = decodeMove(moveIdx, board)\n",
        "                    if (uciMove is None): #could not decode\n",
        "                        probs = np.delete(probs, moveIdx)\n",
        "                        continue\n",
        "                    move = chess.Move.from_uci(str(uciMove))\n",
        "                    if (move in board.legal_moves): #if legal, return, else: loop continues after deleting the move\n",
        "                        return move\n",
        "                except:\n",
        "                    pass\n",
        "                probs = np.delete(probs, moveIdx) #TODO probably better way to do this, but it is not too time critical as it is only for predictions\n",
        "                                             #remove the move so its not chosen again next iteration\n",
        "\n",
        "            #return random move if model failed to find move\n",
        "            moves = board.legal_moves\n",
        "            if (len(moves) > 0):\n",
        "                return np.random.choice(list(moves))\n",
        "            return None #if no legal moves found, return None\n",
        "            # raise Exception(\"Your predict function could not find any legal/decodable moves\")\n",
        "\n",
        "#helper functions for training\n",
        "def train_one_epoch(model, optimizer, loss_fn, epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            # print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "def createBestModelFile():\n",
        "    #first find best model if it exists:\n",
        "    path = Path('./savedModels/bestModel.txt')\n",
        "\n",
        "    if not (path.is_file()):\n",
        "        #create the files\n",
        "        f = open(path, \"w\")\n",
        "        f.write(\"10000000\") #set to high number so it is overwritten with better loss\n",
        "        f.write(\"\\ntestPath\")\n",
        "        f.close()\n",
        "\n",
        "def saveBestModel(vloss, pathToBestModel):\n",
        "    f = open(\"./savedModels/bestModel.txt\", \"w\")\n",
        "    f.write(str(vloss.item()))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(pathToBestModel)\n",
        "    print(\"NEW BEST MODEL FOUND WITH LOSS:\", vloss)\n",
        "\n",
        "def retrieveBestModelInfo():\n",
        "    with open('./savedModels/bestModel.txt', \"r\") as f:\n",
        "        bestLoss_str = f.readline().strip()\n",
        "        if bestLoss_str:\n",
        "            bestLoss = float(bestLoss_str)\n",
        "        else:\n",
        "            bestLoss = float('inf')  # Set it to infinity or any default value as needed\n",
        "        bestModelPath = f.readline()\n",
        "    return bestLoss, bestModelPath\n",
        "\n",
        "\n",
        "path = Path('./savedModels/bestModel.txt')\n",
        "path.parent.mkdir(parents=True, exist_ok=True)\n",
        "path.touch(exist_ok=True)\n",
        "\n",
        "#hyperparams\n",
        "EPOCHS = 500\n",
        "LEARNING_RATE = 0.0001 # was 0.001\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "#run training\n",
        "\n",
        "\n",
        "createBestModelFile()\n",
        "\n",
        "bestLoss, bestModelPath = retrieveBestModelInfo()\n",
        "\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "model = Model()\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    if (epoch_number % 5 == 0):\n",
        "        print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(model, optimizer, loss_fn, epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "\n",
        "    #only print every 5 epochs\n",
        "    if epoch_number % 5 == 0:\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "\n",
        "        if (bestLoss > best_vloss): #if better than previous best loss from all models created, save it\n",
        "            model_path = 'savedModels/model_{}_{}'.format(timestamp, epoch_number)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            saveBestModel(best_vloss, model_path)\n",
        "\n",
        "\n",
        "\n",
        "    epoch_number += 1\n",
        "\n",
        "# print(\"\\n\\nBEST VALIDATION LOSS FOR ALL MODELS: \", bestLoss)"
      ],
      "metadata": {
        "id": "n0TNgBLuwi4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}